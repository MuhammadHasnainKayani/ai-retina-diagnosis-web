{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import kagglehub\n","\n","# Download Dataset\n","dataset_path = kagglehub.dataset_download(\"kushagratandon12/diabetic-retinopathy-balanced\")\n","print(\"Dataset downloaded to:\", dataset_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q-5zVwHeNIn2","executionInfo":{"status":"ok","timestamp":1735299663973,"user_tz":-300,"elapsed":69612,"user":{"displayName":"wajid kiani","userId":"01515809355869016058"}},"outputId":"46c7a72a-ee5e-43a7-8ff1-179f4980ebc7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n","Downloading from https://www.kaggle.com/api/v1/datasets/download/kushagratandon12/diabetic-retinopathy-balanced?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.90G/1.90G [00:27<00:00, 73.6MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Dataset downloaded to: /root/.cache/kagglehub/datasets/kushagratandon12/diabetic-retinopathy-balanced/versions/1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BikiAoqsghxg","executionInfo":{"status":"ok","timestamp":1735299702359,"user_tz":-300,"elapsed":36973,"user":{"displayName":"wajid kiani","userId":"01515809355869016058"}},"outputId":"cb6d0474-1128-4066-ad23-b41db8a4463d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# This code is used to navigate the dataset folder and correcting real path\n","import os\n","\n","dataset_folder = \"/root/.cache/kagglehub/datasets/kushagratandon12/diabetic-retinopathy-balanced/versions/1/content/Diabetic_Balanced_Data\"\n","\n","# List and print folder names\n","folder_names = [f.name for f in os.scandir(dataset_folder) if f.is_dir()]\n","print(\"Folders inside the dataset folder:\", folder_names)\n","\n"],"metadata":{"id":"5BukWmb7JTzo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735299704301,"user_tz":-300,"elapsed":396,"user":{"displayName":"wajid kiani","userId":"01515809355869016058"}},"outputId":"3d076918-cf72-4754-8bc3-7758dea892fe"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Folders inside the dataset folder: ['train', 'val', 'test']\n"]}]},{"cell_type":"code","source":["import os\n","from collections import Counter\n","\n","# Dataset Path\n","DATASET_DIR = \"/root/.cache/kagglehub/datasets/kushagratandon12/diabetic-retinopathy-balanced/versions/1/content/Diabetic_Balanced_Data\"\n","\n","# Function to count images in each class (subfolder)\n","def count_images_in_directory(directory):\n","    class_counts = Counter()\n","    for class_name in os.listdir(directory):\n","        class_path = os.path.join(directory, class_name)\n","        if os.path.isdir(class_path):\n","            # Count the number of images in the class folder\n","            class_counts[class_name] = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n","    return class_counts\n","\n","# Counting images in train, test, and valid directories\n","train_dir = os.path.join(DATASET_DIR, 'train')\n","valid_dir = os.path.join(DATASET_DIR, 'val')\n","test_dir = os.path.join(DATASET_DIR, 'test')\n","\n","train_class_counts = count_images_in_directory(train_dir)\n","valid_class_counts = count_images_in_directory(valid_dir)\n","test_class_counts = count_images_in_directory(test_dir)\n","\n","# Print counts\n","print(\"Class counts in Train directory:\")\n","for class_name, count in train_class_counts.items():\n","    print(f\"{class_name}: {count} images\")\n","\n","print(\"\\nClass counts in Valid directory:\")\n","for class_name, count in valid_class_counts.items():\n","    print(f\"{class_name}: {count} images\")\n","\n","print(\"\\nClass counts in Test directory:\")\n","for class_name, count in test_class_counts.items():\n","    print(f\"{class_name}: {count} images\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vrF9JMq0PHCe","executionInfo":{"status":"ok","timestamp":1735299708880,"user_tz":-300,"elapsed":403,"user":{"displayName":"wajid kiani","userId":"01515809355869016058"}},"outputId":"815f6b20-a87e-4c88-fddb-6eb93df18291"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Class counts in Train directory:\n","3: 7000 images\n","4: 7000 images\n","1: 6792 images\n","2: 7000 images\n","0: 7000 images\n","\n","Class counts in Valid directory:\n","3: 2000 images\n","4: 2000 images\n","1: 1940 images\n","2: 2000 images\n","0: 2000 images\n","\n","Class counts in Test directory:\n","3: 1000 images\n","4: 1000 images\n","1: 971 images\n","2: 1000 images\n","0: 1000 images\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bObkOVeaHAav","outputId":"874ce56b-1236-46ec-e799-9fc6b56f2ab0","executionInfo":{"status":"ok","timestamp":1735311019405,"user_tz":-300,"elapsed":11302867,"user":{"displayName":"wajid kiani","userId":"01515809355869016058"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 34792 images belonging to 5 classes.\n","Found 9940 images belonging to 5 classes.\n","Found 4971 images belonging to 5 classes.\n","Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n","\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m710s\u001b[0m 571ms/step - accuracy: 0.4198 - loss: 1.3115 - val_accuracy: 0.5819 - val_loss: 0.9970\n","Epoch 2/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m559s\u001b[0m 506ms/step - accuracy: 0.5550 - loss: 1.0252 - val_accuracy: 0.6032 - val_loss: 0.9414\n","Epoch 3/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 504ms/step - accuracy: 0.5965 - loss: 0.9362 - val_accuracy: 0.6130 - val_loss: 0.8883\n","Epoch 4/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 506ms/step - accuracy: 0.6326 - loss: 0.8635 - val_accuracy: 0.6736 - val_loss: 0.7845\n","Epoch 5/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 517ms/step - accuracy: 0.6621 - loss: 0.7952 - val_accuracy: 0.6910 - val_loss: 0.7272\n","Epoch 6/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m603s\u001b[0m 499ms/step - accuracy: 0.6808 - loss: 0.7374 - val_accuracy: 0.6886 - val_loss: 0.7350\n","Epoch 7/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m541s\u001b[0m 493ms/step - accuracy: 0.7038 - loss: 0.6981 - val_accuracy: 0.7296 - val_loss: 0.6387\n","Epoch 8/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 501ms/step - accuracy: 0.7212 - loss: 0.6477 - val_accuracy: 0.7342 - val_loss: 0.6315\n","Epoch 9/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 498ms/step - accuracy: 0.7418 - loss: 0.6160 - val_accuracy: 0.7393 - val_loss: 0.6087\n","Epoch 10/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m560s\u001b[0m 511ms/step - accuracy: 0.7527 - loss: 0.5824 - val_accuracy: 0.7531 - val_loss: 0.5688\n","Epoch 11/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 500ms/step - accuracy: 0.7652 - loss: 0.5551 - val_accuracy: 0.7353 - val_loss: 0.6107\n","Epoch 12/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 500ms/step - accuracy: 0.7734 - loss: 0.5326 - val_accuracy: 0.7600 - val_loss: 0.5904\n","Epoch 13/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 511ms/step - accuracy: 0.7868 - loss: 0.5092 - val_accuracy: 0.7783 - val_loss: 0.5199\n","Epoch 14/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 487ms/step - accuracy: 0.8017 - loss: 0.4700 - val_accuracy: 0.7037 - val_loss: 0.8081\n","Epoch 15/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m524s\u001b[0m 479ms/step - accuracy: 0.8091 - loss: 0.4578 - val_accuracy: 0.7709 - val_loss: 0.5801\n","Epoch 16/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 491ms/step - accuracy: 0.8198 - loss: 0.4357 - val_accuracy: 0.7844 - val_loss: 0.5338\n","Epoch 17/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 480ms/step - accuracy: 0.8290 - loss: 0.4150 - val_accuracy: 0.7950 - val_loss: 0.5115\n","Epoch 18/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 479ms/step - accuracy: 0.8383 - loss: 0.3950 - val_accuracy: 0.7962 - val_loss: 0.5191\n","Epoch 19/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m578s\u001b[0m 494ms/step - accuracy: 0.8493 - loss: 0.3685 - val_accuracy: 0.7721 - val_loss: 0.6052\n","Epoch 20/20\n","\u001b[1m1088/1088\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 481ms/step - accuracy: 0.8532 - loss: 0.3571 - val_accuracy: 0.8032 - val_loss: 0.5055\n","\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 160ms/step - accuracy: 0.7990 - loss: 0.5059\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.80\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n","from tensorflow.keras.applications import EfficientNetB0\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.utils.class_weight import compute_class_weight\n","import numpy as np\n","\n","# Fix random seeds for reproducibility\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# Dataset Paths\n","DATASET_DIR = \"/root/.cache/kagglehub/datasets/kushagratandon12/diabetic-retinopathy-balanced/versions/1/content/Diabetic_Balanced_Data\"\n","TRAIN_DIR = f\"{DATASET_DIR}/train\"\n","VAL_DIR = f\"{DATASET_DIR}/val\"\n","TEST_DIR = f\"{DATASET_DIR}/test\"\n","\n","# Hyperparameters\n","IMG_SIZE = 224\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","LEARNING_RATE = 0.0001\n","\n","# Data Augmentation for Training and Normalization for Validation/Test\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n","\n","# Load Data\n","train_data = train_datagen.flow_from_directory(\n","    TRAIN_DIR,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    seed=42\n",")\n","\n","val_data = val_test_datagen.flow_from_directory(\n","    VAL_DIR,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    seed=42\n",")\n","\n","test_data = val_test_datagen.flow_from_directory(\n","    TEST_DIR,\n","    target_size=(IMG_SIZE, IMG_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    seed=42\n",")\n","\n","\n","# Model Definition\n","base_model = EfficientNetB0(include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3), weights=\"imagenet\")\n","base_model.trainable = True\n","\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dropout(0.5),\n","    Dense(128, activation='relu'),\n","    Dropout(0.3),\n","    Dense(train_data.num_classes, activation='softmax')\n","])\n","\n","# Compile Model\n","model.compile(\n","    optimizer=Adam(learning_rate=LEARNING_RATE),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Train the Model\n","history = model.fit(\n","    train_data,\n","    validation_data=val_data,\n","    epochs=EPOCHS,\n",")\n","\n","# Evaluate the Model\n","val_loss, val_accuracy = model.evaluate(test_data)\n","print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n","\n","# Save the Model\n","model.save('/content/drive/MyDrive/final_model_20_epoch.h5')\n"]}]}
